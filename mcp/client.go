package mcp

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"strconv"
	"strings"
	"time"
)

const (
	ProviderCustom = "custom"
)

var (
	DefaultTimeout = 120 * time.Second

	// DefaultProviderURLs å„ provider çš„é»˜è®¤ API URL
	// æ–°å¢ provider æ—¶åªéœ€åœ¨æ­¤ map ä¸­æ·»åŠ å³å¯
	DefaultProviderURLs = map[string]string{
		"openai":    "https://api.openai.com/v1",
		"anthropic": "https://api.anthropic.com/v1",
		"gemini":    "https://generativelanguage.googleapis.com/v1beta/openai",
		"grok":      "https://api.x.ai/v1",
	}

	// DefaultProviderModels å„ provider çš„é»˜è®¤æ¨¡å‹åç§°
	DefaultProviderModels = map[string]string{
		"openai":    "gpt-5.1",
		"anthropic": "claude-sonnet-4-20250514",
		"gemini":    "gemini-2.5-pro",
		"grok":      "grok-4",
	}
)

// Client AI APIé…ç½®
type Client struct {
	Provider    string
	APIKey      string
	BaseURL     string
	Model       string
	Timeout     time.Duration
	UseFullURL  bool    // æ˜¯å¦ä½¿ç”¨å®Œæ•´URLï¼ˆä¸æ·»åŠ /chat/completionsï¼‰
	MaxTokens   int     // AIå“åº”çš„æœ€å¤§tokenæ•°
	Temperature float64 // AI æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶è¾“å‡ºéšæœºæ€§ï¼ˆ0.0-1.0ï¼‰ï¼Œé»˜è®¤ 0.1
}

func New() AIClient {
	// ä»ç¯å¢ƒå˜é‡è¯»å– MaxTokensï¼Œé»˜è®¤ 2000
	maxTokens := 2000
	if envMaxTokens := os.Getenv("AI_MAX_TOKENS"); envMaxTokens != "" {
		if parsed, err := strconv.Atoi(envMaxTokens); err == nil && parsed > 0 {
			maxTokens = parsed
			log.Printf("ğŸ”§ [MCP] ä½¿ç”¨ç¯å¢ƒå˜é‡ AI_MAX_TOKENS: %d", maxTokens)
		} else {
			log.Printf("âš ï¸  [MCP] ç¯å¢ƒå˜é‡ AI_MAX_TOKENS æ— æ•ˆ (%s)ï¼Œä½¿ç”¨é»˜è®¤å€¼: %d", envMaxTokens, maxTokens)
		}
	}

	// é»˜è®¤é…ç½®
	return &Client{
		Provider:    ProviderDeepSeek,
		BaseURL:     DefaultDeepSeekBaseURL,
		Model:       DefaultDeepSeekModel,
		Timeout:     DefaultTimeout,
		MaxTokens:   maxTokens,
		Temperature: 0.1, // äº¤æ˜“ç³»ç»Ÿé»˜è®¤ä½æ¸©ï¼Œä¿è¯å†³ç­–ä¸€è‡´æ€§
	}
}

// SetAPIKey è®¾ç½® API Key å’Œé…ç½®
// provider: æŒ‡å®š AI æä¾›å•† (openai, gemini, groq, custom ç­‰)
// å¦‚æœ apiURL ä¸ºç©ºï¼Œä¼šæ ¹æ® provider ä½¿ç”¨é»˜è®¤ URL
func (client *Client) SetAPIKey(apiKey, apiURL, customModel, provider string) {
	client.Provider = provider
	client.APIKey = apiKey

	// å¦‚æœ URL ä¸ºç©ºï¼Œæ ¹æ® provider ä½¿ç”¨é»˜è®¤ URL
	if apiURL == "" {
		if defaultURL, ok := DefaultProviderURLs[provider]; ok {
			apiURL = defaultURL
		}
	}

	// æ£€æŸ¥URLæ˜¯å¦ä»¥#ç»“å°¾ï¼Œå¦‚æœæ˜¯åˆ™ä½¿ç”¨å®Œæ•´URLï¼ˆä¸æ·»åŠ /chat/completionsï¼‰
	if strings.HasSuffix(apiURL, "#") {
		client.BaseURL = strings.TrimSuffix(apiURL, "#")
		client.UseFullURL = true
	} else {
		client.BaseURL = apiURL
		client.UseFullURL = false
	}

	if customModel != "" {
		client.Model = customModel
	} else if defaultModel, ok := DefaultProviderModels[provider]; ok {
		client.Model = defaultModel
	}
	client.Timeout = 120 * time.Second
}

// CallWithMessages ä½¿ç”¨ system + user prompt è°ƒç”¨AI APIï¼ˆæ¨èï¼‰
func (client *Client) CallWithMessages(systemPrompt, userPrompt string) (string, error) {
	if client.APIKey == "" {
		return "", fmt.Errorf("AI APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·å…ˆè°ƒç”¨ SetAPIKey")
	}

	// é‡è¯•é…ç½®
	maxRetries := 3
	var lastErr error

	for attempt := 1; attempt <= maxRetries; attempt++ {
		if attempt > 1 {
			fmt.Printf("âš ï¸  AI APIè°ƒç”¨å¤±è´¥ï¼Œæ­£åœ¨é‡è¯• (%d/%d)...\n", attempt, maxRetries)
		}

		result, err := client.callOnce(systemPrompt, userPrompt)
		if err == nil {
			if attempt > 1 {
				fmt.Printf("âœ“ AI APIé‡è¯•æˆåŠŸ\n")
			}
			return result, nil
		}

		lastErr = err
		// å¦‚æœä¸æ˜¯ç½‘ç»œé”™è¯¯ï¼Œä¸é‡è¯•
		if !isRetryableError(err) {
			return "", err
		}

		// é‡è¯•å‰ç­‰å¾…
		if attempt < maxRetries {
			waitTime := time.Duration(attempt) * 2 * time.Second
			fmt.Printf("â³ ç­‰å¾…%våé‡è¯•...\n", waitTime)
			time.Sleep(waitTime)
		}
	}

	return "", fmt.Errorf("é‡è¯•%dæ¬¡åä»ç„¶å¤±è´¥: %w", maxRetries, lastErr)
}

func (client *Client) setAuthHeader(reqHeader http.Header) {
	if client.Provider == "anthropic" {
		// Anthropic ä½¿ç”¨ x-api-key è®¤è¯å¤´
		reqHeader.Set("x-api-key", client.APIKey)
		reqHeader.Set("anthropic-version", "2023-06-01")
	} else {
		// OpenAI å…¼å®¹ API ä½¿ç”¨ Bearer token
		reqHeader.Set("Authorization", fmt.Sprintf("Bearer %s", client.APIKey))
	}
}

// SetTemperature è®¾ç½® AI æ¸©åº¦å‚æ•°ï¼ˆ0.0-1.0ï¼‰ï¼Œæ§åˆ¶è¾“å‡ºéšæœºæ€§
func (client *Client) SetTemperature(temperature float64) {
	client.Temperature = temperature
}

// callOnce å•æ¬¡è°ƒç”¨AI APIï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
func (client *Client) callOnce(systemPrompt, userPrompt string) (string, error) {
	// æ‰“å°å½“å‰ AI é…ç½®
	log.Printf("ğŸ“¡ [MCP] AI è¯·æ±‚é…ç½®:")
	log.Printf("   Provider: %s", client.Provider)
	log.Printf("   BaseURL: %s", client.BaseURL)
	log.Printf("   Model: %s", client.Model)
	log.Printf("   UseFullURL: %v", client.UseFullURL)
	if len(client.APIKey) > 8 {
		log.Printf("   API Key: %s...%s", client.APIKey[:4], client.APIKey[len(client.APIKey)-4:])
	}

	var requestBody map[string]interface{}
	var url string

	if client.Provider == "anthropic" {
		// Anthropic Claude API æ ¼å¼
		// - system prompt ä½œä¸ºç‹¬ç«‹å­—æ®µ
		// - messages åªåŒ…å« user æ¶ˆæ¯
		// - ç«¯ç‚¹æ˜¯ /messages
		messages := []map[string]string{
			{"role": "user", "content": userPrompt},
		}

		requestBody = map[string]interface{}{
			"model":       client.Model,
			"messages":    messages,
			"temperature": client.Temperature,
			"max_tokens":  client.MaxTokens,
		}

		// Anthropic çš„ system prompt ä½œä¸ºç‹¬ç«‹å­—æ®µ
		if systemPrompt != "" {
			requestBody["system"] = systemPrompt
		}

		baseURL := strings.TrimSuffix(client.BaseURL, "/")
		url = fmt.Sprintf("%s/messages", baseURL)
	} else {
		// OpenAI å…¼å®¹æ ¼å¼ï¼ˆåŒ…æ‹¬ DeepSeek, Qwen, Gemini, Groq ç­‰ï¼‰
		messages := []map[string]string{}
		if systemPrompt != "" {
			messages = append(messages, map[string]string{
				"role":    "system",
				"content": systemPrompt,
			})
		}
		messages = append(messages, map[string]string{
			"role":    "user",
			"content": userPrompt,
		})

		requestBody = map[string]interface{}{
			"model":       client.Model,
			"messages":    messages,
			"temperature": client.Temperature,
			"max_tokens":  client.MaxTokens,
		}

		if client.UseFullURL {
			url = client.BaseURL
		} else {
			baseURL := strings.TrimSuffix(client.BaseURL, "/")
			url = fmt.Sprintf("%s/chat/completions", baseURL)
		}
	}

	log.Printf("ğŸ“¡ [MCP] è¯·æ±‚å‚æ•°: max_tokens=%d, temperature=%.1f", client.MaxTokens, client.Temperature)

	jsonData, err := json.Marshal(requestBody)
	if err != nil {
		return "", fmt.Errorf("åºåˆ—åŒ–è¯·æ±‚å¤±è´¥: %w", err)
	}

	log.Printf("ğŸ“¡ [MCP] è¯·æ±‚ URL: %s", url)

	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
	if err != nil {
		return "", fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")

	client.setAuthHeader(req.Header)

	// å‘é€è¯·æ±‚
	httpClient := &http.Client{Timeout: client.Timeout}
	resp, err := httpClient.Do(req)
	if err != nil {
		return "", fmt.Errorf("å‘é€è¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	// è¯»å–å“åº”
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", fmt.Errorf("è¯»å–å“åº”å¤±è´¥: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("APIè¿”å›é”™è¯¯ (status %d): %s", resp.StatusCode, string(body))
	}

	// æ ¹æ® provider è§£æä¸åŒå“åº”æ ¼å¼
	if client.Provider == "anthropic" {
		// Anthropic å“åº”æ ¼å¼: content[0].text
		var anthropicResult struct {
			Content []struct {
				Type string `json:"type"`
				Text string `json:"text"`
			} `json:"content"`
			StopReason string `json:"stop_reason"`
			Usage      struct {
				InputTokens  int `json:"input_tokens"`
				OutputTokens int `json:"output_tokens"`
			} `json:"usage"`
		}

		if err := json.Unmarshal(body, &anthropicResult); err != nil {
			return "", fmt.Errorf("è§£æAnthropicå“åº”å¤±è´¥: %w", err)
		}

		if len(anthropicResult.Content) == 0 {
			return "", fmt.Errorf("Anthropic APIè¿”å›ç©ºå“åº”")
		}

		// æ‰“å°å“åº”è¯¦æƒ…
		log.Printf("ğŸ“¡ [MCP] Anthropicå“åº”è¯¦æƒ…: stop_reason=%s, input_tokens=%d, output_tokens=%d",
			anthropicResult.StopReason,
			anthropicResult.Usage.InputTokens,
			anthropicResult.Usage.OutputTokens)

		// æ£€æŸ¥æ˜¯å¦å› ä¸ºé•¿åº¦é™åˆ¶è€Œæˆªæ–­
		if anthropicResult.StopReason == "max_tokens" {
			log.Printf("âš ï¸  [MCP] è­¦å‘Š: AIå“åº”å› max_tokensé™åˆ¶è¢«æˆªæ–­ï¼å½“å‰max_tokens=%d, å®é™…ä½¿ç”¨output_tokens=%d",
				client.MaxTokens, anthropicResult.Usage.OutputTokens)
		}

		return anthropicResult.Content[0].Text, nil
	}

	// OpenAI å…¼å®¹æ ¼å¼å“åº”è§£æ
	var result struct {
		Choices []struct {
			Message struct {
				Content string `json:"content"`
			} `json:"message"`
			FinishReason string `json:"finish_reason"`
		} `json:"choices"`
		Usage struct {
			PromptTokens     int `json:"prompt_tokens"`
			CompletionTokens int `json:"completion_tokens"`
			TotalTokens      int `json:"total_tokens"`
		} `json:"usage"`
	}

	if err := json.Unmarshal(body, &result); err != nil {
		return "", fmt.Errorf("è§£æå“åº”å¤±è´¥: %w", err)
	}

	if len(result.Choices) == 0 {
		return "", fmt.Errorf("APIè¿”å›ç©ºå“åº”")
	}

	// æ‰“å°å“åº”è¯¦æƒ…
	log.Printf("ğŸ“¡ [MCP] å“åº”è¯¦æƒ…: finish_reason=%s, prompt_tokens=%d, completion_tokens=%d, total_tokens=%d",
		result.Choices[0].FinishReason,
		result.Usage.PromptTokens,
		result.Usage.CompletionTokens,
		result.Usage.TotalTokens)

	// æ£€æŸ¥æ˜¯å¦å› ä¸ºé•¿åº¦é™åˆ¶è€Œæˆªæ–­
	if result.Choices[0].FinishReason == "length" {
		log.Printf("âš ï¸  [MCP] è­¦å‘Š: AIå“åº”å› max_tokensé™åˆ¶è¢«æˆªæ–­ï¼å½“å‰max_tokens=%d, å®é™…ä½¿ç”¨completion_tokens=%d",
			client.MaxTokens, result.Usage.CompletionTokens)
	}

	return result.Choices[0].Message.Content, nil
}

// isRetryableError åˆ¤æ–­é”™è¯¯æ˜¯å¦å¯é‡è¯•
func isRetryableError(err error) bool {
	errStr := err.Error()
	// ç½‘ç»œé”™è¯¯ã€è¶…æ—¶ã€EOFç­‰å¯ä»¥é‡è¯•
	retryableErrors := []string{
		"EOF",
		"timeout",
		"connection reset",
		"connection refused",
		"temporary failure",
		"no such host",
		"stream error",   // HTTP/2 stream é”™è¯¯
		"INTERNAL_ERROR", // æœåŠ¡ç«¯å†…éƒ¨é”™è¯¯
	}
	for _, retryable := range retryableErrors {
		if strings.Contains(errStr, retryable) {
			return true
		}
	}
	return false
}
